{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":16592,"databundleVersionId":754004,"sourceType":"competition"}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Step 1: Load training and testing datasets**","metadata":{}},{"cell_type":"code","source":"import time\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import (\n    accuracy_score, confusion_matrix, precision_score,\n    recall_score, f1_score\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/credit-default-prediction-ai-big-data/train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/credit-default-prediction-ai-big-data/test.csv\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Step 2: Display dataset information**","metadata":{}},{"cell_type":"code","source":"def quality_report(df, name):\n    print(f\"\\n{name} Data Information:\")\n    print(df.info())\n    print(\"\\nMissing Values:\")\n    print(df.isnull().sum())\n    print(\"\\nSummary Statistics:\")\n    print(df.describe())\n\nquality_report(train_data, \"Train\")\nquality_report(test_data, \"Test\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Step 3: Handle missing values**","metadata":{}},{"cell_type":"code","source":"# Remove the 'Id' column from features\ntrain_data_no_id = train_data.drop(columns=['Id'], errors='ignore')\ntest_data_no_id = test_data.drop(columns=['Id'], errors='ignore')\n\n# Identify numerical and categorical features\ntrain_numerical_features = train_data_no_id.select_dtypes(include=[np.number]).columns\ntrain_categorical_features = train_data_no_id.select_dtypes(exclude=[np.number]).columns\n\ntest_numerical_features = test_data_no_id.select_dtypes(include=[np.number]).columns\ntest_categorical_features = test_data_no_id.select_dtypes(exclude=[np.number]).columns\n\n# Impute numerical values\nimputer_num_train = SimpleImputer(strategy='mean')\ntrain_data_no_id[train_numerical_features] = imputer_num_train.fit_transform(train_data_no_id[train_numerical_features])\n\nimputer_num_test = SimpleImputer(strategy='mean')\ntest_data_no_id[test_numerical_features] = imputer_num_test.fit_transform(test_data_no_id[test_numerical_features])\n\n# Impute categorical values\nimputer_cat_train = SimpleImputer(strategy='most_frequent')\ntrain_data_no_id[train_categorical_features] = imputer_cat_train.fit_transform(train_data_no_id[train_categorical_features])\n\nimputer_cat_test = SimpleImputer(strategy='most_frequent')\ntest_data_no_id[test_categorical_features] = imputer_cat_test.fit_transform(test_data_no_id[test_categorical_features])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Step 4: Preprocess Data**","metadata":{}},{"cell_type":"code","source":"# Ensure the categorical columns match\ncommon_categorical_features = list(set(train_categorical_features) & set(test_categorical_features))\n\n# Encode categorical variables using OneHotEncoder\nencoder = OneHotEncoder(handle_unknown='ignore', drop='first', sparse_output=False)  # Use sparse_output instead of sparse\n\n# Fit encoder on training set and transform both train and test sets\ncategorical_encoded_train = encoder.fit_transform(train_data_no_id[common_categorical_features])\ncategorical_encoded_test = encoder.transform(test_data_no_id[common_categorical_features])\n\n# Convert encoded categorical features to DataFrame\ncategorical_df_train = pd.DataFrame(categorical_encoded_train, columns=encoder.get_feature_names_out(common_categorical_features))\ncategorical_df_test = pd.DataFrame(categorical_encoded_test, columns=encoder.get_feature_names_out(common_categorical_features))\n\n# Ensure indices are reset for concatenation\ncategorical_df_train.index = train_data_no_id.index\ncategorical_df_test.index = test_data_no_id.index\n\n# Identify numerical features separately for train and test\ntrain_numerical_features = train_data_no_id.select_dtypes(include=[np.number]).columns\ntest_numerical_features = test_data_no_id.select_dtypes(include=[np.number]).columns\n\n# Ensure the numerical columns match\ncommon_numerical_features = list(set(train_numerical_features) & set(test_numerical_features))\n\n# Normalize numerical features\nscaler = StandardScaler()\ntrain_data_no_id[common_numerical_features] = scaler.fit_transform(train_data_no_id[common_numerical_features])\ntest_data_no_id[common_numerical_features] = scaler.transform(test_data_no_id[common_numerical_features])\n\n# Concatenate processed numerical and categorical features\nprocessed_train = pd.concat([train_data_no_id[common_numerical_features], categorical_df_train], axis=1)\nprocessed_test = pd.concat([test_data_no_id[common_numerical_features], categorical_df_test], axis=1)\n\n# Splitting features and target variable\nX_train = processed_train.drop(columns=['Credit Default'], errors='ignore')  # 'errors=ignore' prevents KeyError if 'target' is missing\ny_train = train_data['Credit Default']\n\n# Define X_test (test set does not have a target column)\nX_test = processed_test  # Use the processed test dataset","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Step 5: Model training and evaluation**","metadata":{}},{"cell_type":"code","source":"# Define models\nmodels = {\n    \"Random Forest\": RandomForestClassifier(),\n    \"SVM Linear\": SVC(kernel=\"linear\"),\n    \"SVM Kernel\": SVC(kernel=\"rbf\"),\n    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n    \"Decision Tree\": DecisionTreeClassifier(),\n    \"Na√Øve Bayes\": GaussianNB()\n}\n\n# Initialize results table\nresults = []\n\n# For simplicity, using training data to evaluate models (as y_test is unavailable)\nfor name, model in models.items():\n    start_train = time.time()\n    model.fit(X_train, y_train)  # Train model\n    train_time = time.time() - start_train\n\n    # Prediction on training data since test.csv doesn't have the target column\n    start_pred = time.time()\n    y_pred_train = model.predict(X_train)  # Predict on training data (since no y_test)\n    pred_time = time.time() - start_pred\n\n    # Compute metrics based on training data\n    accuracy = accuracy_score(y_train, y_pred_train)\n    precision = precision_score(y_train, y_pred_train, average='binary')\n    recall = recall_score(y_train, y_pred_train, average='binary')\n    f1 = f1_score(y_train, y_pred_train, average='binary')\n\n    tn, fp, fn, tp = confusion_matrix(y_train, y_pred_train).ravel()\n    misclassification = (fp + fn) / len(y_train)\n    tnr = tn / (tn + fp)  # True Negative Rate\n    fpr = fp / (fp + tn)  # False Positive Rate\n    fnr = fn / (fn + tp)  # False Negative Rate\n    tpr = tp / (tp + fn)  # True Positive Rate\n\n    # Store results\n    results.append({\n        \"Model\": name,\n        \"Accuracy\": accuracy,\n        \"Misclassification\": misclassification,\n        \"TNR\": tnr,\n        \"FPR\": fpr,\n        \"FNR\": fnr,\n        \"TPR\": tpr,\n        \"Precision\": precision,\n        \"Recall\": recall,\n        \"F1 Score\": f1,\n        \"Time to Train\": train_time,\n        \"Time to Predict\": pred_time\n    })\n\n    print(f\"{name} - Accuracy: {accuracy:.2f}, F1 Score: {f1:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}\")\n\n# Convert results to DataFrame\nresults_df = pd.DataFrame(results)\n\n# Ensure all metrics are numeric for CSV output\nmetrics = [\"Accuracy\", \"F1 Score\", \"Precision\", \"Recall\", \"Misclassification\", \"FPR\", \"FNR\"]\nfor metric in metrics:\n    results_df[metric] = pd.to_numeric(results_df[metric], errors='coerce')\n\n# Save results to CSV for future analysis\nresults_df.to_csv(\"model_results.csv\", index=False)\n\n# Create boxplots for model comparison\nmetrics = [\"Accuracy\", \"F1 Score\", \"Precision\", \"Recall\", \"Misclassification\", \"FPR\", \"FNR\"]\ntitles = [\"Accuracy\", \"F1 Score\", \"Precision\", \"Recall\", \"Misclassification Rate\", \"False Positive Rate\", \"False Negative Rate\"]\n\n# Adjusting the figure size and number of rows/columns for the boxplots\nplt.figure(figsize=(16, 12))  # Increase the figure size\n\n# Create subplots for each metric\nfor i, metric in enumerate(metrics):\n    plt.subplot(2, 4, i+1)  # Adjust to 2 rows and 4 columns for better spacing\n    sns.boxplot(data=results_df, x=metric, y=\"Model\", palette=\"Set2\")\n    plt.title(titles[i])\n\n# Adjust layout and show the plot\nplt.tight_layout()\nplt.show()\n\n# Prepare the sample submission file (for test data predictions)\nsubmission = pd.DataFrame({\n    \"Id\": test_data[\"Id\"],  # Keep \"Id\" unchanged\n    \"Credit Default\": models[\"Random Forest\"].predict(X_test)  # Using Random Forest predictions\n})\n\n# Save the CSV file\nsubmission.to_csv(\"submission.csv\", index=False)\nprint(\"Predictions saved to 'submission.csv'.\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-27T16:00:11.273Z"}},"outputs":[],"execution_count":null}]}